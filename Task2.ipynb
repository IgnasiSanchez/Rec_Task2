{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(150000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 150 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 150\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_movielens_100k():\n",
    "    # Load users\n",
    "    u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "    users = pd.read_csv('data/ml-100k/u.user', sep='|', names=u_cols)\n",
    "\n",
    "    # load ratings\n",
    "    r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "    ratings = pd.read_csv('data/ml-100k/u.data', sep='\\t', names=r_cols)\n",
    "\n",
    "    # Load movies\n",
    "    m_cols = ['movie_id', 'title', 'release_date']\n",
    "    movies = pd.read_csv('data/ml-100k/u.item', sep='|', names=m_cols, usecols=range(3), encoding='latin-1')\n",
    "\n",
    "    # Join dataframes\n",
    "    data = pd.merge(pd.merge(ratings, users), movies)\n",
    "    data = data[['user_id','title', 'movie_id','rating','release_date','sex','age']]\n",
    "\n",
    "\n",
    "    print(\"The DB has \"+ str(data.shape[0]) +\" ratings\")\n",
    "    print(\"The DB has \", data.user_id.nunique(),\" users\")\n",
    "    print(\"The DB has \", data.movie_id.nunique(), \" movies\")\n",
    "    print(data.head())\n",
    "    \n",
    "    return data\n",
    "\n",
    "def load_movielens_1M():\n",
    "    # Load users\n",
    "    u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "    users = pd.read_csv('data/ml-1m/users.dat', sep='::', names=u_cols)\n",
    "\n",
    "    # Load ratings\n",
    "    r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "    ratings = pd.read_csv('data/ml-1m/ratings.dat', sep='::', names=r_cols)\n",
    "\n",
    "    # Load movies\n",
    "    m_cols = ['movie_id', 'title', 'release_date']\n",
    "    movies = pd.read_csv('data/ml-1m/movies.dat', sep='::', names=m_cols, usecols=range(3), encoding='latin-1')\n",
    "\n",
    "    # Join dataframes\n",
    "    data = pd.merge(pd.merge(ratings, users), movies)\n",
    "    data = data[['user_id','title', 'movie_id','rating','release_date','sex','age']]\n",
    "\n",
    "\n",
    "    print(\"The DB has \"+ str(data.shape[0]) +\" ratings\")\n",
    "    print(\"The DB has \", data.user_id.nunique(),\" users\")\n",
    "    print(\"The DB has \", data.movie_id.nunique(), \" movies\")\n",
    "    print(data.head())\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DB has 100000 ratings\n",
      "The DB has  943  users\n",
      "The DB has  1682  movies\n",
      "   user_id         title  movie_id  rating release_date sex  age\n",
      "0      196  Kolya (1996)       242       3  24-Jan-1997   M   49\n",
      "1      305  Kolya (1996)       242       5  24-Jan-1997   M   23\n",
      "2        6  Kolya (1996)       242       4  24-Jan-1997   M   42\n",
      "3      234  Kolya (1996)       242       4  24-Jan-1997   M   60\n",
      "4       63  Kolya (1996)       242       3  24-Jan-1997   M   31\n"
     ]
    }
   ],
   "source": [
    "data = load_movielens_100k()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix = data.pivot(index='user_id', columns='movie_id', values='rating')\n",
    "item_user_matrix = data.pivot(index='movie_id', columns='user_id', values='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_item_matrix = user_item_matrix.fillna(user_item_matrix.mean())\n",
    "#item_user_matrix = item_user_matrix.fillna(item_user_matrix.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slow_similarity(user_item_matrix, u1, u2, measure=\"cosine\"):\n",
    "    def dot(m, u1, u2):\n",
    "        return m.loc[u1].dot(m.loc[u2])\n",
    "    \n",
    "    if measure == 'cosine':\n",
    "        return dot(user_item_matrix, u1, u2)/(np.sqrt(dot(user_item_matrix, u1, u1)*dot(user_item_matrix, u2, u2)))\n",
    "    \n",
    "    elif measure == 'adj_cosine':\n",
    "        mr1 = user_item_matrix.loc[u1].mean()\n",
    "        mr2 = user_item_matrix.loc[u2].mean()\n",
    "        common_movies = user_item_matrix.loc[[u1,u2]].isna().sum(axis=0)==0\n",
    "        common_matrix = user_item_matrix.T[common_movies].T\n",
    "        return dot(common_matrix, u1, u2)/(np.sqrt(dot(common_matrix, u1, u1)*dot(common_matrix, u2, u2)))\n",
    "    else:\n",
    "        print(\"Method not implemented\")\n",
    "        \n",
    "def fast_similarity(user_item_matrix, measure=\"cosine\"):\n",
    "    if measure == 'cosine':\n",
    "        m = user_item_matrix.dot(user_item_matrix.T)\n",
    "        norm = np.array([np.sqrt(np.diagonal(m))])\n",
    "        return (m/norm/norm.T)\n",
    "    \n",
    "    elif measure == 'adj_cosine':\n",
    "        m = user_item_matrix - user_item_matrix.mean()\n",
    "        m = m.dot(m.T)\n",
    "        norm = np.array([np.sqrt(np.diagonal(m))])\n",
    "        return (m/norm/norm.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9936685597594792"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_similarity(user_item_matrix.fillna(user_item_matrix.mean()), 10, 11, \"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9936685597594788"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix = fast_similarity(user_item_matrix.fillna(user_item_matrix.mean()), 'cosine')\n",
    "sim_matrix.loc[10][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_based_predict(user_id, item_id, df_matrix, cosine_similarities, banned_list=[]):\n",
    "    if user_id in banned_list:\n",
    "        return 0\n",
    "    mean_item = df_matrix[item_id].mean()\n",
    "    items_user = df_matrix.loc[user_id][df_matrix.loc[user_id] != 0]\n",
    "    candidate_items = items_user.index.tolist()\n",
    "    candidate_ratings = items_user.values\n",
    "    sims = np.array([cosine_similarities[item_id][item_j] for item_j in candidate_items])\n",
    "    candidate_means = np.array([df_matrix[item_j].mean() for item_j in candidate_items])\n",
    "    \n",
    "    if np.sum(sims) <= 0.0001:\n",
    "        return mean_item\n",
    "    else:\n",
    "        return mean_item + np.sum(np.dot(sims, (candidate_ratings-candidate_means)))/np.sum(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.985507097355107"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_based_predict(10, 2, user_item_matrix.fillna(0), sim_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programs\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:29: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "E:\\Programs\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:33: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "E:\\Programs\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:37: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DB has 1000209 ratings\n",
      "The DB has  6040  users\n",
      "The DB has  3706  movies\n",
      "   user_id                                   title  movie_id  rating  \\\n",
      "0        1  One Flew Over the Cuckoo's Nest (1975)      1193       5   \n",
      "1        2  One Flew Over the Cuckoo's Nest (1975)      1193       5   \n",
      "2       12  One Flew Over the Cuckoo's Nest (1975)      1193       4   \n",
      "3       15  One Flew Over the Cuckoo's Nest (1975)      1193       4   \n",
      "4       17  One Flew Over the Cuckoo's Nest (1975)      1193       5   \n",
      "\n",
      "  release_date  sex age  \n",
      "0        Drama    1   F  \n",
      "1        Drama   56   M  \n",
      "2        Drama   25   M  \n",
      "3        Drama   25   M  \n",
      "4        Drama   50   M  \n"
     ]
    }
   ],
   "source": [
    "data = load_movielens_1M()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix = data.pivot(index='user_id', columns='movie_id', values='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=)\n",
    "pca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
