{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(150000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 150 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 150\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_movielens_100k():\n",
    "    # Load users\n",
    "    u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "    users = pd.read_csv('data/ml-100k/u.user', sep='|', names=u_cols)\n",
    "\n",
    "    # load ratings\n",
    "    r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "    ratings = pd.read_csv('data/ml-100k/u.data', sep='\\t', names=r_cols)\n",
    "\n",
    "    # Load movies\n",
    "    m_cols = ['movie_id', 'title', 'release_date']\n",
    "    movies = pd.read_csv('data/ml-100k/u.item', sep='|', names=m_cols, usecols=range(3), encoding='latin-1')\n",
    "\n",
    "    # Join dataframes\n",
    "    data = pd.merge(pd.merge(ratings, users), movies)\n",
    "    data = data[['user_id','title', 'movie_id','rating','release_date','sex','age']]\n",
    "\n",
    "\n",
    "    print(\"The DB has \"+ str(data.shape[0]) +\" ratings\")\n",
    "    print(\"The DB has \", data.user_id.nunique(),\" users\")\n",
    "    print(\"The DB has \", data.movie_id.nunique(), \" movies\")\n",
    "    print(data.head())\n",
    "    \n",
    "    return data, users, ratings, movies\n",
    "\n",
    "def load_movielens_1M():\n",
    "    # Load users\n",
    "    u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "    users = pd.read_csv('data/ml-1m/users.dat', sep='::', names=u_cols)\n",
    "\n",
    "    # Load ratings\n",
    "    r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "    ratings = pd.read_csv('data/ml-1m/ratings.dat', sep='::', names=r_cols)\n",
    "\n",
    "    # Load movies\n",
    "    m_cols = ['movie_id', 'title', 'release_date']\n",
    "    movies = pd.read_csv('data/ml-1m/movies.dat', sep='::', names=m_cols, usecols=range(3), encoding='latin-1')\n",
    "\n",
    "    # Join dataframes\n",
    "    data = pd.merge(pd.merge(ratings, users), movies)\n",
    "    data = data[['user_id','title', 'movie_id','rating','release_date','sex','age']]\n",
    "\n",
    "\n",
    "    print(\"The DB has \"+ str(data.shape[0]) +\" ratings\")\n",
    "    print(\"The DB has \", data.user_id.nunique(),\" users\")\n",
    "    print(\"The DB has \", data.movie_id.nunique(), \" movies\")\n",
    "    print(data.head())\n",
    "    \n",
    "    return data, users, ratings, movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing value treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "def impute_missing_values(df, method=\"mean\", **params):\n",
    "    if method == \"mean\":\n",
    "        return df.mean(), df.fillna(df.mean())\n",
    "    elif method == \"median\":\n",
    "        return df.median(), df.fillna(df.median())\n",
    "    elif method == \"KNN\":\n",
    "        knnimputer = KNNImputer(**params)\n",
    "        knnimputer.fit(df)\n",
    "        return knnimputer, knnimputer.transform(df)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DB has 100000 ratings\n",
      "The DB has  943  users\n",
      "The DB has  1682  movies\n",
      "   user_id         title  movie_id  rating release_date sex  age\n",
      "0      196  Kolya (1996)       242       3  24-Jan-1997   M   49\n",
      "1      305  Kolya (1996)       242       5  24-Jan-1997   M   23\n",
      "2        6  Kolya (1996)       242       4  24-Jan-1997   M   42\n",
      "3      234  Kolya (1996)       242       4  24-Jan-1997   M   60\n",
      "4       63  Kolya (1996)       242       3  24-Jan-1997   M   31\n"
     ]
    }
   ],
   "source": [
    "data, users, ratings, movies = load_movielens_100k()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix = data.pivot(index='user_id', columns='movie_id', values='rating')\n",
    "item_user_matrix = data.pivot(index='movie_id', columns='user_id', values='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slow_similarity(user_item_matrix, u1, u2, measure=\"cosine\"):\n",
    "    def dot(m, u1, u2):\n",
    "        return m.loc[u1].dot(m.loc[u2])\n",
    "    \n",
    "    if measure == 'cosine':\n",
    "        return dot(user_item_matrix, u1, u2)/(np.sqrt(dot(user_item_matrix, u1, u1)*dot(user_item_matrix, u2, u2)))\n",
    "    \n",
    "    elif measure == 'adj_cosine' or measure=='pearson_correlation':\n",
    "        mr1 = user_item_matrix.loc[u1].mean()\n",
    "        mr2 = user_item_matrix.loc[u2].mean()\n",
    "        common_movies = user_item_matrix.loc[[u1,u2]].isna().sum(axis=0)==0\n",
    "        common_matrix = user_item_matrix.T[common_movies].T\n",
    "        return dot(common_matrix, u1, u2)/(np.sqrt(dot(common_matrix, u1, u1)*dot(common_matrix, u2, u2)))\n",
    "    else:\n",
    "        print(\"Method not implemented\")\n",
    "        \n",
    "def fast_similarity(user_item_matrix, measure=\"cosine\"):\n",
    "    if measure == 'cosine':\n",
    "        m = user_item_matrix.dot(user_item_matrix.T)\n",
    "        norm = np.array([np.sqrt(np.diagonal(m))])\n",
    "        return (m/norm/norm.T)\n",
    "    \n",
    "    elif measure == 'adj_cosine' or measure=='pearson_correlation':\n",
    "        m = user_item_matrix - user_item_matrix.mean()\n",
    "        m = m.dot(m.T)\n",
    "        norm = np.array([np.sqrt(np.diagonal(m))])\n",
    "        return (m/norm/norm.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.987294941213731"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_similarity(user_item_matrix.fillna(user_item_matrix.mean()).T, 10, 11, \"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9872949412137292"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix = fast_similarity(user_item_matrix.fillna(user_item_matrix.mean()).T, 'cosine')\n",
    "sim_matrix.loc[10][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_top_k(k, user_vector, user_item_matrix, measure=\"cosine\", movies_df=movies):\n",
    "    new_uim = user_item_matrix.copy()\n",
    "    new_uim.append(user_vector, ignore_index=True)\n",
    "    sim_matrix = fast_similarity(new_uim, measure)\n",
    "    scores_vector = sim_matrix.iloc[-1].sort_values(ascending=False)\n",
    "    idx = scores_vector.iloc[1:k+1].index.tolist() # item 0 is always same item\n",
    "    return movies_df[movies_df['movie_id'].isin(idx)]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1504                   Killer: A Journal of Murder (1995)\n",
       "1509                                  Mad Dog Time (1996)\n",
       "1512                                        Sprung (1997)\n",
       "1514                              Wings of Courage (1995)\n",
       "1519                                     Fear, The (1995)\n",
       "1520                                 Mr. Wonderful (1993)\n",
       "1524                   Object of My Affection, The (1998)\n",
       "1525                                       Witness (1985)\n",
       "1531                               Foreign Student (1994)\n",
       "1532    I Don't Want to Talk About It (De eso no se ha...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_matrix_nafilled = user_item_matrix.fillna(user_item_matrix.mean())\n",
    "recommend_top_k(10, user_item_matrix_nafilled[1].T, user_item_matrix_nafilled.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_based_predict(user_id, item_id, df_matrix, cosine_similarities, banned_list=[]):\n",
    "    if user_id in banned_list:\n",
    "        return 0\n",
    "    mean_item = df_matrix[item_id].mean()\n",
    "    items_user = df_matrix.loc[user_id][df_matrix.loc[user_id] != 0]\n",
    "    candidate_items = items_user.index.tolist()\n",
    "    candidate_ratings = items_user.values\n",
    "    sims = np.array([cosine_similarities[item_id][item_j] for item_j in candidate_items])\n",
    "    candidate_means = np.array([df_matrix[item_j].mean() for item_j in candidate_items])\n",
    "    \n",
    "    if np.sum(sims) <= 0.0001:\n",
    "        return mean_item\n",
    "    else:\n",
    "        return mean_item + np.sum(np.dot(sims, (candidate_ratings-candidate_means)))/np.sum(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.985507097355107"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_based_predict(10, 2, user_item_matrix.fillna(0), sim_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programs\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:29: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "E:\\Programs\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:33: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "E:\\Programs\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:37: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DB has 1000209 ratings\n",
      "The DB has  6040  users\n",
      "The DB has  3706  movies\n",
      "   user_id                                   title  movie_id  rating  \\\n",
      "0        1  One Flew Over the Cuckoo's Nest (1975)      1193       5   \n",
      "1        2  One Flew Over the Cuckoo's Nest (1975)      1193       5   \n",
      "2       12  One Flew Over the Cuckoo's Nest (1975)      1193       4   \n",
      "3       15  One Flew Over the Cuckoo's Nest (1975)      1193       4   \n",
      "4       17  One Flew Over the Cuckoo's Nest (1975)      1193       5   \n",
      "\n",
      "  release_date  sex age  \n",
      "0        Drama    1   F  \n",
      "1        Drama   56   M  \n",
      "2        Drama   25   M  \n",
      "3        Drama   25   M  \n",
      "4        Drama   50   M  \n"
     ]
    }
   ],
   "source": [
    "data, _, _ , movies = load_movielens_1M()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix = data.pivot(index='user_id', columns='movie_id', values='rating')\n",
    "imputer, imputed_uim = impute_missing_values(user_item_matrix, method=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_uim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=200)\n",
    "X = pca.fit_transform(imputed_uim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.84576814,  0.1533608 , -0.28698182, ...,  0.15630821,\n",
       "         0.04778108,  0.02020971],\n",
       "       [-0.2427188 , -0.44173123, -0.029451  , ..., -0.35379784,\n",
       "        -0.97622137, -0.23087237],\n",
       "       [-0.63861605, -0.19106157, -0.96209481, ..., -0.07563167,\n",
       "        -0.44936751,  0.2599604 ],\n",
       "       ...,\n",
       "       [-0.53329208, -0.01007764, -1.35003311, ...,  0.18836334,\n",
       "        -0.05826009,  0.10615133],\n",
       "       [-0.24673272, -0.44319906, -0.63117184, ..., -0.32917713,\n",
       "        -0.23981316, -0.35001329],\n",
       "       [ 4.11564263, -1.17615971, -1.26627455, ...,  0.13716801,\n",
       "         0.58974477,  0.54849883]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
