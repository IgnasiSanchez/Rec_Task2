{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(150000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 150 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 150\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_movielens_100k():\n",
    "    # Load users\n",
    "    u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "    users = pd.read_csv('data/ml-100k/u.user', sep='|', names=u_cols)\n",
    "\n",
    "    # load ratings\n",
    "    r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "    ratings = pd.read_csv('data/ml-100k/u.data', sep='\\t', names=r_cols)\n",
    "\n",
    "    # Load movies\n",
    "    m_cols = ['movie_id', 'title', 'release_date']\n",
    "    movies = pd.read_csv('data/ml-100k/u.item', sep='|', names=m_cols, usecols=range(3), encoding='latin-1')\n",
    "\n",
    "    # Join dataframes\n",
    "    data = pd.merge(pd.merge(ratings, users), movies)\n",
    "    data = data[['user_id','title', 'movie_id','rating','release_date','sex','age']]\n",
    "\n",
    "\n",
    "    print(\"The DB has \"+ str(data.shape[0]) +\" ratings\")\n",
    "    print(\"The DB has \", data.user_id.nunique(),\" users\")\n",
    "    print(\"The DB has \", data.movie_id.nunique(), \" movies\")\n",
    "    print(data.head())\n",
    "    \n",
    "    return data, users, ratings, movies\n",
    "\n",
    "def load_movielens_1M():\n",
    "    # Load users\n",
    "    u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "    users = pd.read_csv('data/ml-1m/users.dat', sep='::', names=u_cols)\n",
    "\n",
    "    # Load ratings\n",
    "    r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "    ratings = pd.read_csv('data/ml-1m/ratings.dat', sep='::', names=r_cols)\n",
    "\n",
    "    # Load movies\n",
    "    m_cols = ['movie_id', 'title', 'release_date']\n",
    "    movies = pd.read_csv('data/ml-1m/movies.dat', sep='::', names=m_cols, usecols=range(3), encoding='latin-1')\n",
    "\n",
    "    # Join dataframes\n",
    "    data = pd.merge(pd.merge(ratings, users), movies)\n",
    "    data = data[['user_id','title', 'movie_id','rating','release_date','sex','age']]\n",
    "\n",
    "\n",
    "    print(\"The DB has \"+ str(data.shape[0]) +\" ratings\")\n",
    "    print(\"The DB has \", data.user_id.nunique(),\" users\")\n",
    "    print(\"The DB has \", data.movie_id.nunique(), \" movies\")\n",
    "    print(data.head())\n",
    "    \n",
    "    return data, users, ratings, movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing value treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "def impute_missing_values(df, method=\"mean\", **params):\n",
    "    if method == \"mean\":\n",
    "        return df.mean(), df.fillna(df.mean())\n",
    "    elif method == \"median\":\n",
    "        return df.median(), df.fillna(df.median())\n",
    "    elif method == \"KNN\":\n",
    "        knnimputer = KNNImputer(**params)\n",
    "        knnimputer.fit(df)\n",
    "        return knnimputer, knnimputer.transform(df)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DB has 100000 ratings\n",
      "The DB has  943  users\n",
      "The DB has  1682  movies\n",
      "   user_id         title  movie_id  rating release_date sex  age\n",
      "0      196  Kolya (1996)       242       3  24-Jan-1997   M   49\n",
      "1      305  Kolya (1996)       242       5  24-Jan-1997   M   23\n",
      "2        6  Kolya (1996)       242       4  24-Jan-1997   M   42\n",
      "3      234  Kolya (1996)       242       4  24-Jan-1997   M   60\n",
      "4       63  Kolya (1996)       242       3  24-Jan-1997   M   31\n"
     ]
    }
   ],
   "source": [
    "data, users, ratings, movies = load_movielens_100k()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix = data.pivot(index='user_id', columns='movie_id', values='rating')\n",
    "item_user_matrix = data.pivot(index='movie_id', columns='user_id', values='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slow_similarity(user_item_matrix, u1, u2, measure=\"cosine\"):\n",
    "    def dot(m, u1, u2):\n",
    "        return m.loc[u1].dot(m.loc[u2])\n",
    "    \n",
    "    if measure == 'cosine':\n",
    "        return dot(user_item_matrix, u1, u2)/(np.sqrt(dot(user_item_matrix, u1, u1)*dot(user_item_matrix, u2, u2)))\n",
    "    \n",
    "    elif measure == 'adj_cosine' or measure=='pearson_correlation':\n",
    "        mr1 = user_item_matrix.loc[u1].mean()\n",
    "        mr2 = user_item_matrix.loc[u2].mean()\n",
    "        common_movies = user_item_matrix.loc[[u1,u2]].isna().sum(axis=0)==0\n",
    "        common_matrix = user_item_matrix.T[common_movies].T\n",
    "        return dot(common_matrix, u1, u2)/(np.sqrt(dot(common_matrix, u1, u1)*dot(common_matrix, u2, u2)))\n",
    "    else:\n",
    "        print(\"Method not implemented\")\n",
    "        \n",
    "def fast_similarity(user_item_matrix, measure=\"cosine\"):\n",
    "    if measure == 'cosine':\n",
    "        m = user_item_matrix.dot(user_item_matrix.T)\n",
    "        norm = np.array([np.sqrt(np.diagonal(m))])\n",
    "        return (m/norm/norm.T)\n",
    "    \n",
    "    elif measure == 'adj_cosine' or measure=='pearson_correlation':\n",
    "        m = user_item_matrix - user_item_matrix.mean()\n",
    "        m = m.dot(m.T)\n",
    "        norm = np.array([np.sqrt(np.diagonal(m))])\n",
    "        return (m/norm/norm.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.987294941213731"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_similarity(user_item_matrix.fillna(user_item_matrix.mean()).T, 10, 11, \"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9872949412137292"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix = fast_similarity(user_item_matrix.fillna(user_item_matrix.mean()).T, 'cosine')\n",
    "sim_matrix.loc[10][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_top_k(k, user_vector, user_item_matrix, measure=\"cosine\", movies_df=movies):\n",
    "    new_uim = user_item_matrix.copy()\n",
    "    new_uim.append(user_vector, ignore_index=True)\n",
    "    sim_matrix = fast_similarity(new_uim, measure)\n",
    "    scores_vector = sim_matrix.iloc[-1].sort_values(ascending=False)\n",
    "    idx = scores_vector.iloc[1:k+1].index.tolist() # item 0 is always same item\n",
    "    return movies_df[movies_df['movie_id'].isin(idx)]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1504                   Killer: A Journal of Murder (1995)\n",
       "1509                                  Mad Dog Time (1996)\n",
       "1512                                        Sprung (1997)\n",
       "1514                              Wings of Courage (1995)\n",
       "1519                                     Fear, The (1995)\n",
       "1520                                 Mr. Wonderful (1993)\n",
       "1524                   Object of My Affection, The (1998)\n",
       "1525                                       Witness (1985)\n",
       "1531                               Foreign Student (1994)\n",
       "1532    I Don't Want to Talk About It (De eso no se ha...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_matrix_nafilled = user_item_matrix.fillna(user_item_matrix.mean())\n",
    "recommend_top_k(10, user_item_matrix_nafilled[1].T, user_item_matrix_nafilled.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_based_predict(user_id, item_id, df_matrix, cosine_similarities, banned_list=[]):\n",
    "    if user_id in banned_list:\n",
    "        return 0\n",
    "    mean_item = df_matrix[item_id].mean()\n",
    "    items_user = df_matrix.loc[user_id][df_matrix.loc[user_id] != 0]\n",
    "    candidate_items = items_user.index.tolist()\n",
    "    candidate_ratings = items_user.values\n",
    "    sims = np.array([cosine_similarities[item_id][item_j] for item_j in candidate_items])\n",
    "    candidate_means = np.array([df_matrix[item_j].mean() for item_j in candidate_items])\n",
    "    \n",
    "    if np.sum(sims) <= 0.0001:\n",
    "        return mean_item\n",
    "    else:\n",
    "        return mean_item + np.sum(np.dot(sims, (candidate_ratings-candidate_means)))/np.sum(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.985507097355107"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_based_predict(10, 2, user_item_matrix.fillna(0), sim_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programs\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:29: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "E:\\Programs\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:33: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "E:\\Programs\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:37: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DB has 1000209 ratings\n",
      "The DB has  6040  users\n",
      "The DB has  3706  movies\n",
      "   user_id                                   title  movie_id  rating  \\\n",
      "0        1  One Flew Over the Cuckoo's Nest (1975)      1193       5   \n",
      "1        2  One Flew Over the Cuckoo's Nest (1975)      1193       5   \n",
      "2       12  One Flew Over the Cuckoo's Nest (1975)      1193       4   \n",
      "3       15  One Flew Over the Cuckoo's Nest (1975)      1193       4   \n",
      "4       17  One Flew Over the Cuckoo's Nest (1975)      1193       5   \n",
      "\n",
      "  release_date  sex age  \n",
      "0        Drama    1   F  \n",
      "1        Drama   56   M  \n",
      "2        Drama   25   M  \n",
      "3        Drama   25   M  \n",
      "4        Drama   50   M  \n"
     ]
    }
   ],
   "source": [
    "data, users, ratings, movies = load_movielens_1M()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix = data.pivot(index='user_id', columns='movie_id', values='rating')\n",
    "na_mask = user_item_matrix.isna().to_numpy()\n",
    "imputer, imputed_uim = impute_missing_values(user_item_matrix, method=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "u2idx = {u:idx for idx,u in enumerate(user_item_matrix.index.values)}\n",
    "idx2u = {idx:u for idx,u in enumerate(user_item_matrix.index.values)}\n",
    "i2idx = {i:idx for idx,i in enumerate(user_item_matrix.columns.values)} \n",
    "idx2i = {idx:i for idx,i in enumerate(user_item_matrix.columns.values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_uim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD missing value iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_f = imputed_uim\n",
    "U,s,Vt = svd(imputed_uim, full_matrices=False)\n",
    "tmp = U.dot(np.diag(s)).dot(Vt)\n",
    "R_f_1 = R_f.copy()\n",
    "R_f_1[na_mask] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.160528189879166e-11\n",
      "2.14062854616419e-11\n",
      "2.4900543836719436e-11\n",
      "2.125893946197836e-11\n",
      "2.2149406293781588e-11\n",
      "2.3554143303590684e-11\n",
      "2.165646015803868e-11\n",
      "2.286399278977073e-11\n",
      "2.2294015466695682e-11\n",
      "2.1922060896382743e-11\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    R_f = R_f_1.copy()\n",
    "    U,s,Vt = svd(R_f_1, full_matrices=False)\n",
    "    tmp = U.dot(np.diag(s)).dot(Vt)\n",
    "    R_f_1[na_mask] = tmp\n",
    "    print(np.linalg.norm(R_f - R_f_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classic SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bu = np.load('saved/svd/bu.npy')\n",
    "bi = np.load('saved/svd/bi.npy')\n",
    "pu = np.load('saved/svd/pu.npy')\n",
    "qi = np.load('saved/svd/qi.npy')\n",
    "mu = user_item_matrix.mean().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naïve code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_svd(user_item_matrix,\n",
    "                init_mu = 0,\n",
    "                init_sigma = 0.1,\n",
    "                latent_dim = 200,\n",
    "                n_epochs = 20,\n",
    "                gamma = 0.007,\n",
    "                lamb = 0.02):\n",
    "\n",
    "\n",
    "    na_mask = np.isnan(user_item_matrix)\n",
    "\n",
    "    #variables\n",
    "    bu = np.zeros(user_item_matrix.shape[0])\n",
    "    bi = np.zeros(user_item_matrix.shape[1])\n",
    "    pu = np.random.normal(init_mu, init_sigma, (user_item_matrix.shape[0], latent_dim))\n",
    "    qi = np.random.normal(init_mu, init_sigma, (user_item_matrix.shape[1], latent_dim))\n",
    "    mu = np.nanmean(user_item_matrix)\n",
    "\n",
    "\n",
    "    # algorithm\n",
    "    for epoch in range(n_epochs):\n",
    "        for i in range(user_item_matrix.shape[1]):\n",
    "            for u in np.where(~na_mask[:,i])[0]:\n",
    "                r = user_item_matrix[u,i]\n",
    "\n",
    "                err = r - (mu + bu[u] + bi[i] + np.dot(qi[i, :], pu[u,:].T))\n",
    "\n",
    "                bu[u] += gamma*(err-lamb*bu[u])\n",
    "                bi[i] += gamma*(err-lamb*bi[i])\n",
    "\n",
    "                qi[i,:] += gamma*(err*pu[u,:] - lamb*qi[i,:])\n",
    "                pu[u,:] += gamma*(err*qi[i,:] - lamb*pu[u,:])\n",
    "    return bu, bi, pu, qi, mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cython\n",
    "Let's try to improve it using cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "cimport numpy as np\n",
    "import numpy as np\n",
    "\n",
    "def compute_svd_cython(double[:,:] user_item_matrix,\n",
    "                 double init_mu=0, \n",
    "                 double init_sigma=0.1, \n",
    "                 int latent_dim=200, \n",
    "                 int n_epochs=20,\n",
    "                 double gamma = 0.007,\n",
    "                 double lamb = 0.02):\n",
    "\n",
    "    na_mask = np.isnan(user_item_matrix)\n",
    "\n",
    "    #variables\n",
    "    bu = np.zeros(user_item_matrix.shape[0], np.double)\n",
    "    bi = np.zeros(user_item_matrix.shape[1], np.double)\n",
    "    pu = np.random.normal(init_mu, init_sigma, (user_item_matrix.shape[0], latent_dim))\n",
    "    qi = np.random.normal(init_mu, init_sigma, (user_item_matrix.shape[1], latent_dim))\n",
    "    cdef double mu = np.nanmean(user_item_matrix)\n",
    "\n",
    "    cdef int i, u, epoch\n",
    "    cdef double r = 0\n",
    "    cdef double err = 0\n",
    "\n",
    "\n",
    "    # algorithm\n",
    "    for epoch in range(n_epochs):\n",
    "        #print(str(epoch)+\"/\"+str(n_epochs))\n",
    "        for i in range(user_item_matrix.shape[1]):\n",
    "            for u in np.where(~na_mask[:,i])[0]:\n",
    "\n",
    "                r = user_item_matrix[u,i]\n",
    "\n",
    "                err = r - (mu + bu[u] + bi[i] + np.dot(qi[i, :], pu[u,:].T))\n",
    "\n",
    "                bu[u] += gamma*(err-lamb*bu[u])\n",
    "                bi[i] += gamma*(err-lamb*bi[i])\n",
    "\n",
    "                qi[i,:] += gamma*(err*pu[u,:] - lamb*qi[i,:])\n",
    "                pu[u,:] += gamma*(err*qi[i,:] - lamb*pu[u,:])\n",
    "    return bu, bi, qi, pu, mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Surprise\n",
    "\n",
    "The `surprise` library has a better \"cythonised\" code for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1,5))\n",
    "data = Dataset.load_from_df(ratings[['user_id', 'movie_id', 'rating']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_svd_surprise(data):\n",
    "    algo = SVD(n_factors=200, n_epochs=1)\n",
    "    algo.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.8 s ± 194 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit compute_svd(user_item_matrix, n_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 s ± 42.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit compute_svd_cython(user_item_matrix, n_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8 s ± 34.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit compute_svd_surprise(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction\n",
    "\n",
    "We will use surprise for the computation, but we will use our own predict function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x237c0cd1c50>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "algo = SVD(n_factors=200, n_epochs=20)\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "bu = algo.bu\n",
    "bi = algo.bi\n",
    "pu = algo.pu\n",
    "qi = algo.qi\n",
    "mu = user_item_matrix.mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6040,), (3679,), (6040, 3706))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bu.shape, bi.shape, user_item_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('saved/svd/bu.npy', bu)\n",
    "np.save('saved/svd/bi.npy', bi)\n",
    "np.save('saved/svd/pu.npy', pu)\n",
    "np.save('saved/svd/qi.npy', qi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(u, i):\n",
    "    # This is a nuance of using train/test split. Since our dataset is split by surprise, let's use their functions\n",
    "    uk = trainset.knows_user(u)\n",
    "    ik = trainset.knows_item(i)\n",
    "    \n",
    "    r_hat = mu\n",
    "    \n",
    "    if uk:\n",
    "        r_hat += bu[u]\n",
    "    \n",
    "    if ik: \n",
    "        r_hat += bi[i]\n",
    "    \n",
    "    if uk and ik:\n",
    "        r_hat += np.dot(qi[i, :], pu[u,:].T)\n",
    "    \n",
    "    return r_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0452924597557054"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(10,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rank Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_test = [x[0:2] for x in testset if x[2] == 5.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_N(N):\n",
    "    hits = 0\n",
    "    for u,i in to_test:\n",
    "        candidate_unseen_movies = np.where(na_mask[u2idx[u],:])[0]\n",
    "        candidate_unseen_movies = np.random.choice(candidate_unseen_movies, size=100, replace=False)\n",
    "        np.append(candidate_unseen_movies, i2idx[i])\n",
    "        unseen_movies_order_idx = np.argsort([predict(u,idx2i[ii]) for ii in candidate_unseen_movies])\n",
    "        sorted_unseen_movies = candidate_unseen_movies[unseen_movies_order_idx]\n",
    "        p = np.where(sorted_unseen_movies == i2idx[i])[0]\n",
    "        hits += p<=N\n",
    "    recall_N = hits/len(to_test)\n",
    "    precision_N = recall_N/(N+1)\n",
    "    return recall_N, precision_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-8fc7599a0db1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'N'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'recall(N)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1808\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1810\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1611\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1612\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m                                   \"with non-matching shapes is deprecated.\")\n\u001b[0;32m    382\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mncx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mncy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m             \u001b[0mseg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mncx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mncy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m             \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = [precision_at_N(N) for N in range(1,21)]\n",
    "\n",
    "prec = [x[1] for x in scores]\n",
    "rec = [x[0] for x in scores]\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "ax = plt.subplot(1,2,1)\n",
    "ax.plot(np.linspace(1,21,num=20), rec, 'r-')\n",
    "ax.set_xlabel('N')\n",
    "ax.set_ylabel('recall(N)')\n",
    "ax.set_title('Recall')\n",
    "\n",
    "ax = plt.subplot(1,2,2)\n",
    "ax.plot(rec, prec, 'r-')\n",
    "ax.set_xlabel('recall')\n",
    "ax.set_ylabel('precision')\n",
    "ax.set_title('Precision vs recall')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#items rated by user u\n",
    "R_u = {u:user_item_matrix.columns[~user_item_matrix.loc[u].isna()] for u in user_item_matrix.index.values}\n",
    "R_u_idx = {u:user_item_matrix.columns.isin(R_u[u]) for u in R_u.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bu = np.load('saved/svdpp/bu.npy')\n",
    "bi = np.load('saved/svdpp/bi.npy')\n",
    "pu = np.load('saved/svdpp/pu.npy')\n",
    "qi = np.load('saved/svdpp/qi.npy')\n",
    "yj = np.load('saved/svdpp/yj.npy')\n",
    "\n",
    "mu = user_item_matrix.mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653d6880b29948489452ceae0e89dc06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programs\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:34: RuntimeWarning: overflow encountered in multiply\n",
      "E:\\Programs\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: overflow encountered in multiply\n",
      "E:\\Programs\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: invalid value encountered in subtract\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#hyperparams\n",
    "init_mu = 0\n",
    "init_sigma = 0.1\n",
    "latent_dim = 200\n",
    "n_epochs = 20\n",
    "gamma = 0.007\n",
    "lamb_bias = 0.02\n",
    "lamb_latent = 0.02\n",
    "\n",
    "\n",
    "#variables\n",
    "bu = np.zeros(user_item_matrix.shape[0])\n",
    "bi = np.zeros(user_item_matrix.shape[1])\n",
    "pu = np.random.normal(init_mu, init_sigma, (user_item_matrix.shape[0], latent_dim))\n",
    "qi = np.random.normal(init_mu, init_sigma, (user_item_matrix.shape[1], latent_dim))\n",
    "yj = np.random.normal(init_mu, init_sigma, (user_item_matrix.shape[1], latent_dim))\n",
    "mu = user_item_matrix.mean().mean()\n",
    "\n",
    "\n",
    "# algorithm\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    for i in user_item_matrix.columns.values:\n",
    "        for u in user_item_matrix[~user_item_matrix[i].isna()].index.values:\n",
    "            ii = i2idx[i]\n",
    "            uu = u2idx[u]\n",
    "            r = user_item_matrix[i].loc[u]\n",
    "            \n",
    "            wt = np.sqrt(R_u[u].shape[0])\n",
    "            implicit_fbck = np.sum(yj[R_u_idx[u], :])/wt\n",
    "            err = r - (mu + bu[uu] + bi[ii] + np.dot(qi[ii, :].T, pu[uu,:] + implicit_fbck))\n",
    "            \n",
    "            bu[uu] += gamma*(err-lamb_bias*bu[uu])\n",
    "            bi[ii] += gamma*(err-lamb_bias*bi[ii])\n",
    "            \n",
    "            qi[ii,:] += gamma*(err*(pu[uu,:] + implicit_fbck) - lamb_latent*qi[ii,:])\n",
    "            pu[uu,:] += gamma*(err*qi[ii,:] - lamb_latent*pu[uu,:])\n",
    "            yj[ii,:] += gamma*(err/wt*qi[ii,:] - lamb_latent*yj[ii,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('saved/svdpp/bu.npy', bu)\n",
    "np.save('saved/svdpp/bi.npy', bi)\n",
    "np.save('saved/svdpp/pu.npy', pu)\n",
    "np.save('saved/svdpp/qi.npy', qi)\n",
    "np.save('saved/svdpp/yj.npy', yj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(u, i):\n",
    "    uu = u2idx[u]\n",
    "    ii = i2idx[i]\n",
    "    \n",
    "    wt = np.sqrt(R_u[u].shape[0])\n",
    "    implicit_fbck = np.sum(yj[R_u_idx[u]])/wt\n",
    "    return mu + bi[ii] + bu[uu] + np.dot(qi[ii, :].T, pu[uu,:]+implicit_fbck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
